# Module 6: Building Azure Machine Learning Models

- [Module 6: Building Azure Machine Learning Models](#module-6-building-azure-machine-learning-models)
    - [Demo 1: Reviewing the four TDSP phases in Azure Machine Learning](#demo-1-reviewing-the-four-tdsp-phases-in-azure-machine-learning)
        - [Scenario](#scenario)
        - [Business Understanding](#business-understanding)
        - [Data Acquisition and Understanding](#data-acquisition-and-understanding)
        - [Modeling](#modeling)
        - [Deployment](#deployment)
    - [Demo 2: Using a sample application based on a neural network](#demo-2-using-a-sample-application-based-on-a-neural-network)
        - [Scenario](#scenario)
        - [Open an income dataset and select metadata](#open-an-income-dataset-and-select-metadata)
        - [Remove duplicate rows](#remove-duplicate-rows)
        - [Clip values for an upper age threshold of 75](#clip-values-for-an-upper-age-threshold-of-75)
        - [Verify the data clipping](#verify-the-data-clipping)
        - [Split data into training and test datasets](#split-data-into-training-and-test-datasets)
        - [Add the Two-Class Neural Network module](#add-the-two-class-neural-network-module)
        - [Evaluate the model](#evaluate-the-model)

## Demo 1: Reviewing the four TDSP phases in Azure Machine Learning

### Scenario

In this demonstration, you will review the four TDSP phases in Machine Learning Studio:
-	Business Understanding
-	Data Acquisition and Understanding
-	Modeling
-	Deployment

### Business Understanding

1.	On the **20774A-LON-DEV** virtual machine, on the **Start** menu, type **Internet Explorer**, and then click **Internet Explorer**.
2.	In Internet Explorer, in the address bar, type **https://studio.azureml.net**.
3.	On the **Microsoft Azure Machine Learning Studio** page, click **Sign In**. 
4.	Sign in with your Microsoft account credentials to Machine Learning Studio.
5.	Ensure that **EXPERIMENTS** is selected in the navigation pane, and then click **+ NEW** to create an experiment.
6.	In the search box, search for the term **Adult**.
7.	Select the experiment called **Sample 5: Train, Test, Evaluate for Binary Classification: Adult Dataset**.
8.	The Business Understanding phase is the business question. The point of this experiment is to define people’s income levels as “High” or “Low,” depending on their characteristics. The “High” earners earn more than USD50,000, and the “Low” earners earn less than USD50,000.


### Data Acquisition and Understanding

1.	Click the **Adult Census Income Binary Classification** dataset module.
2.	Click the **Select Columns in Dataset** module. Point out that this module is used here to exclude some columns from the analysis. 
3.	Click the **Split Data** module.
4.	The above steps all form part of the Data Acquisition and Understanding phase because the data is still being prepared at this point.

### Modeling

1.	Click the **Two-Class Boosted Decision Tree** module. This is the model that has been chosen to determine the business question. It is well-suited for the business question because the output is one of two choices: high earners or low earners.
2.	You are determining patterns in the data, so this is part of the Modeling phase.
3.	Click the **Train Model** module. You are training the model, so this is still part of the Modeling phase.
4.	Click the **Score Model** module. You are scoring the model, so this is still part of the Modeling phase.
5.	Click the **Evaluate Model** module. You are evaluating the model based on its scores, so this is still part of the Modeling phase.

### Deployment

1.	Click **RUN** at the bottom of the page, to run the experiment.
2.	When the experiment has completed, click **Set Up Web Service** at the bottom of the page, and then select the **Predictive Web Service (Recommended)** option.
3.	Click **RUN** at the bottom of the page, to run the experiment again.
4.	This will produce the final model, ready for deployment. Point out the animations as the model is created, and the fact that the new **Predictive experiment** tab is displayed. 
5.	Click **RUN** at the bottom of the page, to run the experiment again.
6.	Explain that the model is now ready for the Deployment phase of the TDSP.

>**Note:** In this demonstration, you will review an end-to-end Machine Learning experiment, with the TDSP in mind. The objective of this experiment is to break it into its component parts so that you can understand it in terms of the TDSP.

> Deployment is covered in Module 10 of this course. For more information about the TDSP, see: [Team Data Science Process (TDSP)](https://aka.ms/oi7kgv)

## Demo 2: Using a sample application based on a neural network

### Scenario

In this demonstration, you will see how to:
-	Open an income dataset and select metadata.
-	Remove duplicate rows.
-	Clip values for an upper age threshold of 75.
-	Verify the data clipping.
-	Split data into training and test datasets.
-	Add the Two-Class Neural Network module.
-	Evaluate the model.

### Open an income dataset and select metadata

1.	On the **20774A-LON-DEV** virtual machine, in **Microsoft Azure Machine Learning Studio**, ensure that **EXPERIMENTS** is selected in the navigation pane, and then click **+ NEW**, and then click **Blank Experiment** to create a new blank experiment.
2.	In the search box, search for the term **Adult Census Income Binary Classification**, and then drag the **Adult Census Income Binary Classification** dataset module onto the canvas.
3.	In the search box, search for the term **Edit Metadata**, and then drag the **Edit Metadata** module onto the canvas.
4.	Connect the input of the **Edit Metadata** module to the output of the **Adult Census Income Binary Classification** dataset module.
5.	Click the **Edit Metadata** module, and in the **Properties** pane, click **Launch column selector**.
6.	Remove the **fnlwgt** column from the analysis by moving all the column names from the left side to the right side, except for the **fnlwgt** column name.
7.	Click the tick to save and close the window.
8.	In the search box, search for the term **Summarize Data**, and then drag the **Summarize Data** module onto the canvas.
9.	Connect the input of the **Summarize Data** module to the output of the Adult Census Income Binary Classification dataset module.

### Remove duplicate rows

1.	In the search box, search for the term **Remove Duplicate Rows**, and then drag the **Remove Duplicate Rows** module onto the canvas.
2.	Connect the input of the **Remove Duplicate Rows** module to the output of the **Edit Metadata** module.
3.	Click the **Remove Duplicate Rows** module, and in the **Properties** pane, click **Launch column selector**.
4.	In the **Select Columns** box, select the **With Rules** option on the left side.
5.	In the **Begin With** option, select **ALL COLUMNS**.
6.	Select the **Include** option, and then select **column names**.
7.	Click in the box next to **column names**, and then select all of the column names apart from the **fnlwgt** column, which is not part of our analysis.
8.	Click the check mark to confirm the changes.

### Clip values for an upper age threshold of 75

1.	In the search box, search for the term **Clip Values**, and then drag the **Clip Values** module onto the canvas.
2.	Connect the input of the **Clip Values** module to the output of the **Remove Duplicate Rows** module.
3.	Click the **Clip Values** module.
4.	In the **Properties** pane, under the **Set of thresholds** option, select **ClipPeaks**.
5.	Under the **Constant value for upper threshold** option, type **75**.
6.	Click **Launch column selector**, and then select the **With Rules** option.
7.	Under the **Begin With** option, select **NO COLUMNS**. 
8.	Select the **Include** option, and then select **column names**.
9.	Click in the box next to **column names**, and then select **age**.
10.	Click the check mark to confirm the changes.
11.	Run the experiment.

### Verify the data clipping

1.	Click the output of the **Adult Census Income Binary Classification** module, and then click **Visualize**.
2.	Click the **age** column, and then review the Statistics section on the right. Note that the maximum age is set to **90**.
3.	Close the visualization.
4.	Click the output of the **Clip Values** module, and then click **Visualize**.
5.	Click the **age** column, and then review the Statistics section on the right. Note that the maximum age is now set to **75**.
6.	Close the visualization.

### Split data into training and test datasets

1.	In the search box, search for the term **Convert to Dataset**, and then drag the **Convert to Dataset** module onto the canvas.
2.	Connect the input of the **Convert to Dataset** module to the output of the **Clip Values** module.
3.	To split the data into a training dataset and a test dataset, in the search box, search for the term **Split Data**, and then drag the **Split Data** module onto the canvas.
4.	Connect the input of the **Split Data** module to the output of the **Convert to Dataset** module.
5.	Click the **Split Data** module.
6.	In the **Properties** pane, under the **Fraction of rows in the first output dataset** option, type **0.7**.

### Add the Two-Class Neural Network module

1.	In the search box, search for the term **Two-Class Neural Network**, and then drag the **Two-Class Neural Network** module onto the canvas, placing it to the left of the **Split Data** task.
2.	In the search box, search for the term **Train Model**, and then drag it onto the canvas, placing it below the **Two-Class Neural Network** module.
3.	Connect the output of the **Two-Class Neural Network** module to the left input node of the **Train Model** module.
4.	To score the model, in the search box, search for the term **Score Model**, and then drag it onto the canvas, placing it below the **Train Model** module.
5.	Connect the output of the **Train Model** module to the left input node of the **Score Model** module.
6.	Connect the left output of the **Split Data** module to the right input node of the **Train Model** module.
7.	Click the **Train Model** module, and in the **Properties** pane, click **Launch column selector**.
8.	Next to **columns name** box, in the drop-down list, click **income**.
9.	Click the check mark to confirm the changes.
10.	Connect the right output of the **Split Data** module to the right input node of the **Score Model** module.
11.	To add the **Evaluate Model** module, in the search box, search for the term Evaluate Model, and then drag it onto the canvas, placing it below **Score Model**. 
12.	Connect the output of the **Score Model** module to the left input node of the **Evaluate Model** module.
13.	To save the experiment, click **SAVE AS**.
14.	In the **EXPERIMENT NAME** box, type **Neural Network Demo**, and then click the check mark.
15.	To run the experiment, click **RUN**.

### Evaluate the model

1.	Click the output port of the **Evaluate Model** module, and then click **Visualize**.
2.	The receiver operating characteristic (ROC) curve is not that close to the upper-left corner of the ROC chart, so the model could be improved.
3.	The F1 score, which denotes accuracy, is approximately 0.657, which also suggests room for improvement.
4.	Close the visualization, and then close Internet Explorer.

---

©2018 Microsoft Corporation. All rights reserved.

The text in this document is available under the [Creative Commons Attribution 3.0 License](https://creativecommons.org/licenses/by/3.0/legalcode), additional terms may apply. All other content contained in this document (including, without limitation, trademarks, logos, images, etc.) are **not** included within the Creative Commons license grant. This document does not provide you with any legal rights to any intellectual property in any Microsoft product. You may copy and use this document for your internal, reference purposes.

This document is provided "as-is." Information and views expressed in this document, including URL and other Internet Web site references, may change without notice. You bear the risk of using it. Some examples are for illustration only and are fictitious. No real association is intended or inferred. Microsoft makes no warranties, express or implied, with respect to the information provided here.