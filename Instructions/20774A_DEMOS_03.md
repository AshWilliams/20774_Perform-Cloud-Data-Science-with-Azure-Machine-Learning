# Module 3: Managing Datasets

- [Module 3: Managing Datasets](#module-3-managing-datasets)
    - [Demo 1: Load data from Hadoop using Hive](#demo-1-load-data-from-hadoop-using-hive)
        - [Scenario](#scenario)
        - [Preparation](#preparation)
        - [Upload data to Azure Blob storage](#upload-data-to-azure-blob-storage)
        - [Import data to Hive table](#import-data-to-hive-table)
        - [Access the Hadoop data using Hive query](#access-the-hadoop-data-using-hive-query)
        - [Explore the data](#explore-the-data)
    - [Demo 2: Load data from a website by using HTTP](#demo-2-load-data-from-a-website-by-using-http)
        - [Scenario](#scenario)
        - [Preparation](#preparation)
        - [Import CSV data from a web URL](#import-csv-data-from-a-web-url)
        - [Visualize the imported data](#visualize-the-imported-data)
        - [Add column names to imported data](#add-column-names-to-imported-data)

## Demo 1: Load data from Hadoop using Hive

### Scenario

In this demonstration, you will see how to:
- Upload data to Azure Blob storage.
- Import data to a Hive table.
- Access the Hadoop data using Hive query.
- Explore the data.

### Preparation

You should create the Hadoop cluster before teaching this module; do not go into detail on Hadoop at this stage, as this is covered in Module 12 of this course.

The cluster deployment might take 20-30 minutes to complete.

1.	Ensure that the **MT17B-WS2016-NAT**, **20774A-LON-DC**, and **20774A-LON-DEV** virtual machines are running.
2.	On the **20774A-LON-DEV** virtual machine, ensure that you are logged on as **ADATUM\AdatumAdmin**.
3.	On the Start menu, start to type **Internet Explorer**, and then click **Internet Explorer**.
4.	In **Internet Explorer**, in the address bar, type **http://azure.microsoft.com**, click **Portal**, and sign in using the Microsoft account that is associated with your Azure Learning Pass subscription.
5.	In the **Azure Portal**, in the left-hand pane, click **+ New**.
6.	Click **Intelligence + analytics**, and then click **HDInsight**.
7.	Enter the following details, and then click **Cluster type**:
    - Cluster name: **\<your name\>\<date\>**
8.	Enter the following details, and then click **Select**:
    -	Cluster type: **Hadoop**
    -	Operating system: **Linux**
    -	Version: **(leave at default)**
    -	Cluster tier: **STANDARD**
9.	Enter the following details, and then click **Next**:
    -	Cluster login username: **hadmin**
    -	Cluster login password: **Pa55w.rdPa55w.rd**
    -	Secure Shell (SSH) username: **sadmin**
    -	Resource group (Create new): **hadooprg**
    -	Location: **Select your region**
10.	On the **Storage** blade, under **Select a Storage account**, click **Create new.**
11.	In the **Create a new Storage account** box, type **\<your name\>\<date\>**.
12.	In the **Default container** box, replace the suggested name with the name of your cluster (for example, **\<your name\>\<date\>**.
13.	Leave all other settings at defaults, and click **Next**.
14.	On the **Cluster summary** blade, next to **Cluster size**, click **Edit**.
15.	On the **Cluster size** blade, in the **Number of Worker nodes** box, type **1**.
16.	Click **Worker node size**.
17.	On the **Choose your node size** blade, click **View all**, then click **A3 General Purpose**, and then click **Select**.
18.	Click **Head node size**.
19.	On the **Choose your node size** blade, click **View all**, then click **A3 General Purpose**, and then click **Select**.
20.	On the **Cluster size** blade, click **Next**.
21.	On the **Advanced settings** blade, click **Next**.
22.	On the **Cluster summary** blade, note the estimated cost per hour of this cluster; to avoid using up your Azure Pass allowance, it is important that you remove the cluster when you are not using it.
23.	On the **Cluster summary** blade, click **Create**.
24.	The deployment might take 20-30 minutes to complete.

>**Important:** After you have taught this demonstration, delete the HDInsight cluster.

### Upload data to Azure Blob storage

1.	On the **20774A-LON-DEV** virtual machine, ensure that you are logged in as **ADATUM\AdatumAdmin**.
2.	On the Start menu, type **Azure Storage**, and then click **Microsoft Azure Storage Explorer**.
3.	In the **Connect to Azure Storage** dialog box, ensure that **Add an Azure Account** is selected, and click **Sign in**.
4.	In the **Sign in to your account** dialog box, enter the credentials of the Microsoft account that is associated with your Azure Learning Pass subscription, and click **Sign in**.
5.	Under your Azure Learning Pass subscription, under **Storage Accounts**, expand the storage account as created in the preparation steps **\<your name\>\<date\>**.
6.	Expand **Blob Containers**, and then click the blob container as created in the preparation steps **\<your name\>\<date\>**. 
7.	In the right-hand pane, click **New Folder**.
8.	In the **Create New Virtual Directory** dialog box, in the **Name** box, type **data**, and then click **OK**.
9.	In the right-hand pane, click **Upload**, and then click **Upload Files**.
10.	In the click **Upload files** dialog box, on the right of the **Files** box, click the ellipses **(…)**. 
11.	In the **Select files to upload** dialog box, browse **E:\\Demofiles\\Mod03**, click **DimDate.csv**, and then click **Open**.
12.	In the **Upload files** dialog box, click **Upload**; wait until the file has been uploaded before proceeding to the next step.
13.	Close Storage Explorer.

### Import data to Hive table

1.	On the toolbar, click **Microsoft Edge**.
2.	In Microsoft Edge, in the address bar, type **https://\<Hadoop cluster name\>.azurehdinsight.net**, replacing **\<Hadoop cluster name\>** with the name of your cluster, and then press **Enter**.
3.	In the **Windows Security** dialog box, enter the following credentials, and then click **OK**:
    -	User name: **hadmin**
    -	Password: **Pa55w.rdPa55w.rd**
4.	In the **Ambari** console, in the top bar, click the set of squares icon, and then click **Hive View**.
5.	Click **Query**.
6.	In the **Query Editor**, type the following to create a table to hold the Hive information, and then click **Execute**:
```SQL
    CREATE EXTERNAL TABLE if not exists  DimDate(PKIDDate INT, Day INT, DaySuffix STRING, DayOfWeek INT, 
    DayOfWeekName STRING, DOWInMonth INT, DayOfYear INT, WeekOfYear INT, WeekOfMonth INT, Month INT, 
    MonthName STRING, Quarter INT, QuarterName STRING, Year INT, StandardDate STRING, Season STRING)
    ROW FORMAT DELIMITED
    FIELDS TERMINATED BY ','
    STORED AS TEXTFILE
    LOCATION '/data'
    TBLPROPERTIES("skip.header.line.count"="1");
```
7.	The above command can be copied from: **E:\\Demofiles\\Mod03\\HiveTable.txt**.
8.	Before proceeding, wait until you see a “Status: SUCCEEDED” message, before proceeding.
9.	Close Microsoft Edge.

### Access the Hadoop data using Hive query

1.	On the Start menu, type **Internet Explorer**, and then click **Internet Explorer**.
2.	In Internet Explorer, in the address bar, type **http://azure.microsoft.com**, click **Portal**, and sign in using the Microsoft account that is associated with your Azure Learning Pass subscription.
3.	In the **Azure Portal**, in the left-hand pane, click **All resources**, and then click your storage account.
4.	Under **Settings**, click **Access keys**.
5.	In the properties pane, next to **key1**, click the **Click to copy** icon.
6.	In Internet Explorer, click **+** to create a new tab.
7.	In Internet Explorer, in the address bar, type **https://studio.azureml.net**.
8.	On the **Microsoft Azure Machine Learning Studio** page, click **Sign In**. 
9.	If you are prompted for credentials, use the details of the Microsoft Account that you created for this course.
10.	In Microsoft Azure Machine Learning Studio, ensure that **EXPERIMENTS** is selected in the navigation pane, then click **+ New**.
11.	Click **Blank Experiment**.
12.	In the **Search experiment items** box, type **Import**, and then from the module list, drag **Import Data** on to the experiment canvas.
13.	In the right-hand **Properties** pane, in the **Data source** list, click **Hive Query**. 
14.	In the **Properties** pane, add the following information:
    - HCatalog server URI: insert the name of your cluster **\<your cluster name\>.azurehdinsight.net**.
    - Hadoop user account name: **hadmin**.
    - Hadoop user account password: **Pa55w.rdPa55w.rd**. 
    - Location of output data: **Azure Blob storage (WASB)**.
    - Storage account name: **\<your storage name\>**.
    - Storage key: Paste the key you copied earlier.
    - Container name: **\<your cluster name\>**.
15.	In the **Hive database query** box, type **SELECT * FROM DimDate**.
16.	Select the **Use cached results** check box; this will make it quicker when rerunning the experiment.
17.	Click **SAVE** at the bottom of the page.
18.	Click **SAVE AS** at the bottom of the page.
19.	In the **SAVE AS** dialog box, in the **EXPERIMENT NAME** box, type **Import Data using Hive Query**, and click **Ok** (the tick). 
20.	To run the experiment, at the bottom of the page, click **RUN**.
21.	When the experiment has finished running, all modules will show a green check mark to indicate that they have successfully finished; a “Finished” running status is also shown in the upper-right corner of the workspace.

### Explore the data

1.	In the **Search experiment** items box, type **Summarize**, and then from the module list, drag **Summarize Data** on to the experiment canvas.
2.	Click the **Import Data** module, and you will see an output port on the bottom of the task. 
3.	To connect **Summarize Data** to **Import Data**, click the **Import Data** module, and the output node will show the number **1**. Click the output node, and, keeping the mouse pressed down, draw a line from the **Import Data** module to the input (top) port of the **Summarize Data** module.
4.	Click **SAVE** at the bottom of the page.
5.	At the bottom of the page, click **RUN**.
6.	When the experiment has finished running, all modules will show a green check mark to indicate that they have successfully finished.
7.	Double-click the (lower) output port of the **Summarize Data** module, and then click **Visualize**.
8.	Point out some of the key pieces of information, such as number of data points (54,787), missing values, and so on. 
9.	Point out that you can get a partial list of statistics by using the Visualize option in the Summarize Data task, but that it is limited to the top number of rows. To get more detail, the statistics can be written in a tabular dataset and explored in more detail using Excel, SQL Server or Power BI™.
10.	Close the visualization by clicking the **x** at the top-right of the window.
11.	Close Internet Explorer.

>**Note:** Explain that date information is very useful for many scenarios. In data warehousing, data information is an essential part of any business intelligence solution—because many business questions involve time. In this demonstration, you will upload date information into Azure Blob storage, specify the data that you want using HiveQL to shape the data, and then query the data.

>There are several different ways to use Hive to access Hadoop queries:
>    -	The Hadoop Command Line
>    -	The Hive Editor
>    -	Azure PowerShell™ commands

>In this demonstration, the Hive Editor will be used to shape and query the data held in Azure Blob storage.

## Demo 2: Load data from a website by using HTTP

### Scenario

In this demonstration, you will see how to:
-	Import CSV data from a web URL.
-	Visualize the imported data.
-	Add column names to imported data.

### Preparation

Ensure that the **MT17B-WS2016-NAT**, **20774A-LON-DC**, and **20774A-LON-DEV** virtual machines are running, and that you are logged on to **20774A-LON-DEV** as **ADATUM\AdatumAdmin**.

### Import CSV data from a web URL

1.	On the **20774A-LON-DEV** virtual machine, on the Start menu, type **Internet Explorer**, and then click **Internet Explorer**.
2.	In Internet Explorer, in the address bar, type **https:// studio.azureml.net**.
3.	On the **Microsoft Azure Machine Learning Studio** page, click **Sign In**. 
4.	If you are prompted for credentials, use the details of the Microsoft Account that you created for this course.
5.	In Microsoft Azure Machine Learning Studio, ensure that **EXPERIMENTS** is selected in the navigation pane, then click **+ New**.
6.	Click **Blank Experiment**.
7.	In the Sea**rch experiment items** box, start to type **Import**, and then from the module list, drag **Import Data** on to the experiment canvas.
8.	In the right-hand **Properties** pane, in the **Data source** list, select **Web URL via HTTP**. 
9.	In the **Data source** URL box, type **http://mlr.cs.umass.edu/ml/machine-learning-databases/autos/imports-85.data** 
(The above URL can be copied from **E:\Demofiles\Mod03\WebURL.txt**.)
10.	In the **Data format** list, select **CSV**. 
11.	Select **Use cached results**; this will make it quicker when rerunning the experiment.
12.	At the bottom of the page, click **SAVE**, then click **SAVE AS**.
13.	In the **EXPERIMENT NAME** box, type **Import from Web URL**, and then click the **tick**.

### Visualize the imported data

1.	Run the experiment, by clicking **RUN** at the bottom of the page.
2.	When the experiment has finished running, all modules will show a green check mark to indicate that they have successfully finished; a **Finished running** status is also shown in the upper-right corner of the workspace.
3.	Wait until the experiment has successfully completed. 
4.	Double-click the (lower) output port of the **Import Data** module, and then click **Visualize**.
5.	Point out that the column names are not present in the data, so the data does not make much sense. In the next set of steps, column names will be added.
6.	Click the **x** at the top-right of the page, to close the visualization page.

### Add column names to imported data

1.	In the **Search experiment** items box, start to type **Edit**, and then from the module list, drag **Edit Metadata** on to the experiment canvas.
2.	Click the **Import Data** module, and you will see an output port on the bottom of the task. 
3.	Connect **Edit Metadata** to **Import Data**. To do this, click the **Import Data** module, and the output node will show the number **1**. Click the output node and, keeping the mouse pressed down, draw a line from the **Import Data** module to the input (top) port of the **Edit Metadata** module.
4.	Click the **Edit Metadata** module, and in the **Properties** pane, click **Launch Column Selector**.
5.	In the **Select columns** dialog box, ensure that **BY NAMES** is selected on the left-hand side.
6.	Under **AVAILABLE COLUMNS**, select all the columns, and click the right arrow, so that they are listed under **SELECTED COLUMNS**, then click the check mark (tick) to confirm the change.
7.	In the **Properties** pane, in the **New column names** box, type the following:
    ``` 
    symboling,normalized-losses,make,fuel-type,aspiration,num-of-doors,body-style,drive-wheels,engine-location,wheel-base,length,width,height,curb-weight,engine-type,num-of-cylinders,engine-size,fuel-system,bore,stroke,compression-ratio,horsepower,peak-rpm,city-mpg,highway-mpg,price
    ```
    (The above list can be copied from **E:\Demofiles\Mod03\ColumnNames.txt**.)
8.	Run the experiment, by clicking **RUN** at the bottom of the page.
9.	When the experiment has finished running, all modules will show a green check mark to indicate that they have successfully finished.
10.	Click **SAVE** at the bottom of the page. 
11.	Double-click the (lower) output port of the **Edit Metadata** module, and then click **Visualize**.
12.	Point out that, now, the results make more sense with the column names that have been added to the data. 
13.	Close the visualization by clicking the **x** at the top-right of the window.

>**Note:** Point out that, in this demonstration, you first import data from a CSV file that does not contain any header metadata; you then add column names to make the data more meaningful.

---

©2018 Microsoft Corporation. All rights reserved.

The text in this document is available under the [Creative Commons Attribution 3.0 License](https://creativecommons.org/licenses/by/3.0/legalcode), additional terms may apply. All other content contained in this document (including, without limitation, trademarks, logos, images, etc.) are **not** included within the Creative Commons license grant. This document does not provide you with any legal rights to any intellectual property in any Microsoft product. You may copy and use this document for your internal, reference purposes.

This document is provided "as-is." Information and views expressed in this document, including URL and other Internet Web site references, may change without notice. You bear the risk of using it. Some examples are for illustration only and are fictitious. No real association is intended or inferred. Microsoft makes no warranties, express or implied, with respect to the information provided here.