# Module 5: Using Feature Engineering and Selection in Azure Machine Learning

- [Module 5: Using Feature Engineering and Selection in Azure Machine Learning](#module-5-using-feature-engineering-and-selection-in-azure-machine-learning)
    - [Demo 1: Using Join to merge data](#demo-1-using-join-to-merge-data)
        - [Scenario](#scenario)
        - [Preparation](#preparation)
        - [UImport transaction data from Azure SQL Database](#uimport-transaction-data-from-azure-sql-database)
        - [Add date data to the experiment](#add-date-data-to-the-experiment)
        - [Join the transaction and date datasets](#join-the-transaction-and-date-datasets)
    - [Demo 2: Using count-based featurization](#demo-2-using-count-based-featurization)
        - [Scenario](#scenario)
        - [Preparation](#preparation)
        - [Work through an example counting transformation](#work-through-an-example-counting-transformation)

## Demo 1: Using Join to merge data

### Scenario

In this demonstration, you will see how to:
-	Create a transaction dataset by importing from Azure SQL Database.
-	Upload a date dataset from a flat file.
-	Add the second dataset to an experiment.
-	Join the transaction and date datasets.

### Preparation

This demo requires an Azure SQL Database called **WideWorldImporters-Standard**. Before running this demo, you must complete the following steps:
1.	On the **20774A-LON-DEV** virtual machine, in Internet ExplorerÂ®, in the address bar, type **http://azure.microsoft.com**, click **Portal**, and sign in using the Microsoft account that is associated with your Azure Learning Pass subscription.
2.	In the Azure Portal, in the left-hand pane, click **+ New**.
3.	Select **Databases**, and then select **SQL Database**.
4.	Enter the following details, and then click **Server**:
    -	Name: **WideWorldImporters-Standard**
    -	Resource group (create new): **\<your name\>rg**
    -	Select source: **Blank database**
5.	On the New server pane, enter the following details, and then click Select:
    -	Server name: **\<your name\>\<date\>**
    -	Server admin login: **dbadmin**
    -	Password: **Pa55w.rd**
    -	Confirm password: **Pa55w.rd**
    -	Location: **Select your region**
6.	Click **Pricing tier**, click **Standard**, and then click the left-hand end of the **DTU slider**, so that the **DTU** box shows **10 (S0)**.
7.	Click **Apply**.
8.	Leave all other details at their defaults, and click **Create**.
9.	Make a note of the database and server names that you used.
10.	Wait until you see a message that the deployment has been successful.
11.	In the **Navigation** pane, click **All resources**, and then click **WideWorldImporters-Standard**.
12.	On the **WideWorldImporters-Standard** blade, click the **Server name**, and then on the **Settings** blade, click Fi**r**ewall.
13.	Click **Add client IP**, and then click **Save**, to add your current IP address to the list of allowed IP addresses. 
14.	Click **OK**, and then close the Firewall settings, Settings and server blades.
15.	On the **20774A-LON-DEV** virtual machine, right-click **Start**, and then click **Command Prompt (Admin)**.
16.	In the User Account Control dialog box, click Yes.
17.	In the **Command Prompt** window, type the following command, and press Enter:
    ```dos
    CD C:\Program Files (x86)\Microsoft SQL Server\130\DAC\Bin
    ```
18.	In the **Command Prompt** window, type the following command (replacing <your db servername> with the name of your database server), and press Enter:
    ```dos
    SqlPackage.exe /a:import /tcs:"Data Source=<your db servername>.database.windows.net;Initial Catalog=WideWorldImporters-Standard;User Id=dbadmin;Password=Pa55w.rd" /sf:E:\Demofiles\Mod05\WideWorldImporters-Standard.bacpac /p:DatabaseEdition=Standard /p:DatabaseServiceObjective=S0
    ```
    The above command can be copied from **E:\\Demofiles\\Mod05\\SqlPackageCmd.txt**.
19.	Wait until you get the Successfully imported database message.
20.	Close the command prompt.
21.	In the Azure Portal, in the **Navigation** pane, click **All resources**, and then click **WideWorldImporters-Standard**.
22.	On the **Overview** pane, click **Tools**.
23.	On the **Tools** pane, click **Query editor (preview)**.
24.	In the **Query editor (preview)**, click **Login**.
25.	Enter the following details, and then click **OK**:
    -	Authorization type: **SQL server authentication**
    -	Login: **dbadmin**
    -	Password: **Pa55w.rd**
26.	Click in line 1, type the following command, and then click **Run**:
    ```SQL
    CREATE SCHEMA [20774A] AUTHORIZATION db_owner;
    GO
    EXECUTE sp_addextendedproperty @name = N'Description', 
    @value = N'Schema for AzureML data import.', @level0type = N'SCHEMA', @level0name = N'20774A';
    ```
    The above command can be copied from **E:\Demofiles\Mod05\SqlSchemaCmd.txt**.

27.	Delete the commands.
28.	Click in line 1, type the following command, and then click **Run**:
    ```SQL
    IF EXISTS (SELECT * FROM sys.views WHERE name = '20774A.CustomerTransactions')
    DROP VIEW [20774A].[CustomerTransactions]
    GO

    IF OBJECT_ID('[20774A].[CustomerTransactions]', 'V') IS NOT NULL
        DROP VIEW [20774A].[CustomerTransactions]
    GO

    CREATE VIEW [20774A].[CustomerTransactions]

    AS 

    SELECT customers.CustomerName, 
        CAST( [TransactionAmount] AS REAL) AS TransactionAmount,
        CAST([OutstandingBalance] AS REAL) AS OutstandingBalance,
        CAST([TaxAmount] AS REAL) AS TaxAmount,
        CONCAT(
        (LEFT([TransactionDate],4)),RIGHT(LEFT([TransactionDate],7),2),RIGHT(LEFT([TransactionDate],10),2)
        )															AS PKIDDate
        ,[TransactionDate]
    
    FROM [Sales].[Customers] AS customers
                                LEFT OUTER JOIN
                                [Sales].[CustomerTransactions] AS customertransactions
                                ON customers.CustomerID = customertransactions.CustomerID;
    ```
    The above command can be copied from **E:\Demofiles\Mod05\SqlViewCmd.txt**.
29.	In Internet Explorer, click **+** to create a new tab, and in the address bar, type **https://studio.azureml.net/**.
30.	On the **Microsoft Azure Machine Learning Studio** page, click **Sign In**. 
31.	If you are prompted for credentials, use the details of the Microsoft account that you created for this course.
32.	In Microsoft Azure Machine Learning Studio, ensure that **DATASETS** is selected in the navigation pane, then click **+ New**.
33.	Click **FROM LOCAL FILE**.
34.	In the **Upload a new dataset** dialog box, click **Browse**.
35.	In the **Choose file to upload** dialog box, navigate to **E:\Demofiles\Mod05**, click **DimDate3.csv**, and then click **Open**. 
36.	In the **ENTER A NAME FOR THE NEW DATASET** box, type **DateHolidayPromo**. 
37.	In the **SELECT A TYPE FOR THE NEW DATASET** list, select **Generic CSV File with a header (.csv)**.
38.	Click the check mark (tick).

### UImport transaction data from Azure SQL Database

Import transaction data from Azure SQL Database
1.	On the 20774A-LON-DEV virtual machine, in the Microsoft Azure Machine Learning Studio page, click Sign In. 
2.	If you are prompted for credentials, use the details of the Microsoft account that you created for this course.
3.	Ensure that EXPERIMENTS is selected in the navigation pane, then click + NEW.
4.	Click Blank Experiment.
5.	In the Search experiment items box, type Import, and then from the module list, drag Import Data on to the experiment canvas.
6.	In the right-hand Properties pane, in the Data source list, select Azure SQL Database.
7.	In the Database server name box, type the following (replacing <your db servername> with the name of your database server created in the preparation steps):
<your db servername>.database.windows.net
8.	In the Database name box, type WideWorldImporters-Standard.
9.	In the User name box, type dbadmin.
10.	In the Password box, type Pa55w.rd.
11.	In the Database query box, type the following command to use a subset of the total data:
SELECT * From [20774A].[CustomerTransactions]
12.	Select Use cached results.
13.	In the Search experiment items box, type Summarize, and then from the module list, drag Summarize Data on to the right-hand side of the experiment canvas.
14.	Connect the Import Data module to the input port of the Summarize Data module. 
15.	Click SAVE AS at the bottom of the page.
16.	In the EXPERIMENT NAME box, type Shaping Demo, and click the tick.
17.	Run the experiment, by clicking RUN at the bottom of the page.
18.	When the experiment has run successfully, right-click the output port of the Summarize Data module, and then click Visualize.
19.	Point out that there are six rows or features being imported from the Azure SQL Database.
20.	Close the visualization by clicking the x at the top-right of the window.
21.	Click SAVE at the bottom of the page.

### Add date data to the experiment

1.	In Microsoft Azure Machine Learning Studio, click EXPERIMENTS, click MY EXPERIMENTS, and then click Shaping Demo.
2.	In the Search experiment items box, type Date, and then from the module list, drag DateHolidayPromo on to the left side of the experiment canvas, to the left of the Import Data module.
3.	In the Search experiment items box, type Summarize, and then from the module list, drag Summarize Data on to the left-hand side of the experiment canvas, and below DateHolidayPromo.
4.	Connect the output port of DateHolidayPromo to the input port of Summarize Data.
5.	Run the experiment, by clicking RUN at the bottom of the page. 
6.	Point out that, by running the experiment, Machine Learning Studio can pick up the metadata for the DateHolidayPromo dataset.
7.	When the experiment has finished running, click the output port of the Summarize Data module that you just added, and then click Visualize.
8.	Note that there are 18 rows (features) in this dataset.
9.	Close the visualization by clicking the x at the top-right of the window.

### Join the transaction and date datasets

Join the transaction and date datasets
1.	In the Search experiment items box, type Join, and then from the module list, drag Join Data on to the experiment canvas, between and below DateHolidayPromo and Import Data.
2.	Connect the output port of DateHolidayPromo to the left-hand input port of Join Data.
3.	Connect the output port of Import Data to the right-hand input port of Join Data.
4.	Explain that you now need to configure the join; for both the Import Data and DateHolidayPromo datasets, the common key is a date field, called PKIDDate.
5.	Click the Join Data module, and in the Properties pane, under Join key columns for L, click Launch column selector.
6.	In the Select columns dialog box, under AVAILABLE COLUMNS, click PKIDDate, and then click the right arrow.
7.	Click the check mark (tick).
8.	In the Properties pane, under Join key columns for R, click Launch column selector.
9.	In the Select columns dialog box, under AVAILABLE COLUMNS, click PKIDDate, and then click the right arrow.
10.	Click the check mark (tick).
11.	In the Search experiment items box, type Summarize, and then from the module list, drag Summarize Data on to the experiment canvas, below Join Data.
12.	Connect the output port of the Join Data module to the input port of Summarize Data.
13.	Run the experiment, by clicking RUN at the bottom of the page.
14.	When the experiment has finished running, click the output port of the Summarize Data module that you just added, and then click Visualize.
15.	Note that there are now 24 rows (features) in the joined data, and that the columns from both source tables are now listed in the Feature column.
16.	Close the visualization by clicking the x at the top-right of the window.
17.	Click SAVE at the bottom of the page.

## Demo 2: Using count-based featurization

### Scenario

In this demonstration, you will see how to:
-	Use an example counting transformation.

### Preparation

Before running this demo, you must complete the following steps:
1.	On the 20774A-LON-DEV virtual machine, in Internet Explorer, in the address bar, type https://studio.azureml.net/.
2.	On the Microsoft Azure Machine Learning Studio page, click Sign In. 
3.	If you are prompted for credentials, use the details of the Microsoft account that you created for this course.
4.	After logging into Microsoft Azure Machine Learning Studio, click the + NEW button in the lower left-hand corner of the screen.
5.	In the Search box, type count, and for the option Learning with Counts: Binary classification with NYC Taxi Data, click OPEN IN STUDIO.
6.	Wait for the experiment to load, and then click Run.
7.	Wait for the experiment to finish; note that this might take 10-15 minutes.

### Work through an example counting transformation

1.	Start by pointing out that, to save time, you have already loaded and run an experiment in Microsoft Azure Machine Learning Studio.
2.	In Microsoft Azure Machine Learning Studio, in the Learning with Counts: Binary classification with NYC Taxi Data experiment, click the Build Counting Transform module.
3.	In the Properties pane, point out that the label, or target column, is called tipped; this data identifies whether the taxi driver received a tip or not.
4.	In the Properties pane, under Select columns to count, click Launch column selector.
5.	In the Select columns dialog box, point out that the columns that are contributing towards the count are listed on the right-hand side.
6.	Close the Select columns dialog box.
7.	Click the Modify Count Table Parameters module.
8.	In the Properties pane, point out that no scale has been added; the Laplacian noise scale is set to zero. 
9.	Point to the two Apply Transformation tasks; explain that these tasks apply the previously configured counting transformation to both the taxi and fare datasetsâone using the count table with the fare data, and the other using the taxi data.
10.	Point to the Two-Class Logistic Regression module; this is used to identify whether or not a tip was given. The model is trained using the Train Model task, and then it is scored using the Score Model task.
11.	Point to the Evaluate Model module. Explain that the efficiency of the model can be determined by using Evaluate Model.
12.	Click Evaluate Model, and then click Visualize.
13.	Explain that, in the Receiver Operating Curve (ROC), the closer the curve is found to the top left-hand corner, the more successful the model. In this case, you see that the curve is found high up in the left-hand corner. As a first step, the model would appear to be a successful one. However, you need to look more closely at the actual data:
    -	The Accuracy score is 0.969.  This shows the ratio of correctly predicted observations. Intuitively, this is a high score.
    -	Precision looks at the rate of correct positive observations. Here, the precision shows a high number of correct positive observations.
    -	Recall is the ratio of correctly predicted positive events. It is the ratio that was correctly predicted out of the total predictions.
    -	F1 is the weighted average of Precision and Recallâits score takes both false positives and false negatives into account.
14.	Although the scores are good, you would need to review data againâto look for class distributions, and to bear in mind the cost of false positives and false negatives.
15.	Close the visualization by clicking the x at the top-right of the window.

>**Note:** In this demo, you will show a Count Featurizer from the Azure Machine Learning Studio Gallery, which uses the NYC Taxi rides dataset. The objective is to use trip and fare data to work out which trips are most likely to result in tips.

>The challenge is that the data has a lot of features; all trips are all made to, and from, a large variety of destinationsâand thereâs timing, amount of fare, and tip amount to take into account. 


---

Â©2018 Microsoft Corporation. All rights reserved.

The text in this document is available under the [Creative Commons Attribution 3.0 License](https://creativecommons.org/licenses/by/3.0/legalcode), additional terms may apply. All other content contained in this document (including, without limitation, trademarks, logos, images, etc.) are **not** included within the Creative Commons license grant. This document does not provide you with any legal rights to any intellectual property in any Microsoft product. You may copy and use this document for your internal, reference purposes.

This document is provided "as-is." Information and views expressed in this document, including URL and other Internet Web site references, may change without notice. You bear the risk of using it. Some examples are for illustration only and are fictitious. No real association is intended or inferred. Microsoft makes no warranties, express or implied, with respect to the information provided here.