# Module 11: Using Cognitive Services

- [Module 11: Using Cognitive Services](#module-11-using-cognitive-services)
    - [Demo 1: Using curl and Microsoft Kiosk with Language APIs](#demo-1-using-curl-and-microsoft-kiosk-with-language-apis)
        - [Scenario](#scenario)
        - [Preparation](#preparation)
        - [Use the Cognitive Services Text Analytics API with curl commands](#use-the-cognitive-services-text-analytics-api-with-curl-commands)
        - [Use the Cognitive Services Bing Search API with the Kiosk application](#use-the-cognitive-services-bing-search-api-with-the-kiosk-application)
    - [Demo 2: Using Microsoft Kiosk with Image and Video APIs](#demo-2-using-microsoft-kiosk-with-image-and-video-apis)
        - [Scenario](#scenario-1)
        - [Preparation](#preparation-1)
        - [Configure the Kiosk application to use Microsoft Cognitive Services’ Face, Emotion, and Computer Vision APIs](#configure-the-kiosk-application-to-use-microsoft-cognitive-services-face-emotion-and-computer-vision-apis)
        - [Use the Kiosk application to detect faces and facial expressions](#use-the-kiosk-application-to-detect-faces-and-facial-expressions)
        - [Use the Kiosk application to analyze images](#use-the-kiosk-application-to-analyze-images)
    
## Demo 1: Using curl and Microsoft Kiosk with Language APIs

### Scenario

In this demonstration, you will see how to:
-  Use the Cognitive Services Text Analytics API with curl commands.
-  Use the Cognitive Services Bing Search API with the Kiosk application.

### Preparation

Before starting this demo, use the following steps to enable bash:
1.  Start the **MT17B-WS2016-NAT**, **20774A-LON-DC**, and **20774A-LON-DEV** virtual machines.
2.  Log in to the **20774A-LON-DEV** virtual machine as **Adatum\AdatumAdmin** with a password of **Pa55w.rd**.
3.  Click Start, type **Services**, and then press Enter.
4.  Right-click **Windows Update**, and then click **Properties**.
5.  In the **Windows Updated Properties (Local Computer)** dialog box, in the **Startup type** list, click **Manual**, and then click **Apply**.
6.  Click **Start**, and then click **Settings**.
7.  In Windows Settings, click **Update & security**, and then click **For developers**.
8.  Under **Use developer features**, click **Developer mode**.
9.  In the **Use developer features** dialog box, click **Yes**.
10. Wait until the Developer Package has been installed.
11. Close Settings.
12. In the **Windows Updated Properties (Local Computer)** dialog box, in the **Startup type** list, click **Disabled**, and then click **OK**.
13. If the Windows Update service is running, right-click **Windows Update**, and then click **Stop**.
14. Close Services.
15. Right-click **Start**, and then click **Control Panel**.
16. Click **Programs**, and then click **Turn Windows Features on or off**. 
17. In the **Windows Features** dialog box, select the **Windows Subsystem for Linux (Beta)** check box, and click **OK**.
18. In the **Windows Features** dialog box, click **Restart now**.
19. The **20774A-LON-DEV** virtual machine will restart and update with the new feature; this process may take several minutes.
20. Log in to the **20774A-LON-DEV** virtual machine as **Adatum\AdatumAdmin** with a password of **Pa55w.rd**.
21. Open a command prompt, type **bash**, and then press **Enter**.
22. As this is the first use, type **Y**, and press Enter; Ubuntu for Windows will now download, this process may take several minutes.
23. At the command prompt, type **root**, and then press Enter.
24. At the command prompt, type **exit**, and then press Enter.
25. Close the command prompt.

Use the following procedure to install the Universal Windows Platform Tools and Windows 10 SDK:

1.  On the **20774A-LON-DEV** virtual machine, start **Internet Explorer** and navigate to **https://go.microsoft.com/fwlink/p/?linkid=845298**.
2.  In the Internet Explorer message box, click **Run**.
3.  In the **Windows Software Development Kit** installation wizard, on the **Specify Location** page, click **Next**.
4.  On the **Windows Kits Privacy** page, click **No**, and then click **Next**.
5.  On the **License Agreement** page, click **Accept**.
6.  On the **Select the features you want to install** page, click **Install**.
7.  In the **User Account Control** dialog box, click **Yes**.
8.  When the installation has completed, click **Close**.
9.  Close Internet Explorer.
10. Start **Visual Studio 2015**, and open the **IntelligentKioskSample.sln** located in the **E:\Demofiles\Mod11\Kiosk** folder.
11. In the **Solution Explorer** window, if the **IntelligentKioskSample** project fails to load (if it is marked as unavailable), perform the following steps:
    1.  Right-click the **IntelligentKioskSample** project, and then click **Resolve Errors**.
    2.  In the **Security Warning for ServiceHelpers** dialog box, clear the **Ask me for every project in this solution** check box, and then click **OK**.
    3.  In Solution Explorer, right-click the **IntelligentKioskSample** project, and then click **Set as StartUp Project**.
    4.  Press F5, and verify that the Intelligent Kiosk Sample window opens.
    5.  Close the Intelligent Kiosk Sample window.

### Use the Cognitive Services Text Analytics API with curl commands

1.  In Internet Explorer, navigate to **https://portal.azure.com**.
2.  If prompted, sign in using the Microsoft account that is associated with your Azure Learning Pass subscription.
3.  Click **+ Create a resource**.
4.  In the search box, type **Text Analytics** and then press Enter.
5.  Click **Text Analytics**, and then click **Create**.
6.  Specify the following parameters, and then click **Create**:
    -  **Account name**: \<*yourname*\>-CSA
    -  **Subscription**: your classroom subscription
    -  **Location**: your nearest location
    -  **Pricing Tier**: S1
    -  **Resource Group (Create new)**: \<*yourname*\>-CSARG
7.  After the Cognitive Service is created, click **All resources**, click **\<*yourname*\>-CSA**, click **Keys**, and copy the value shown for **KEY 1** to the clipboard. 
8.  Open a command prompt, type **bash**, and then press Enter to start a bash terminal.
9.  In the bash terminal, type the following command and press Enter. Replace **\<location\>** with the location in which you created the Text Analytics service (for example "westus" or "westeurope"), and replace **\<your API key\>** with the API key you copied previously:

    ````bash
    curl -v -X POST "https://<location>.api.cognitive.microsoft.com/text/analytics/v2.0/sentiment" -H "Content-Type: application/json" -H "Ocp-Apim-Subscription-Key: <your API key>" --data-ascii '{"documents":[{"language":"en","id":"1234","text":"I really love traveling to Spain. The architecture is beyond beautiful and the food exquisite."}]}'
    ````    
 
    >**Note**: The above command can be copied from: **E:\Demofiles\Mod11\CurlCmd.txt**.

    Explain that this curl command checks the sentiment score of a sentence.
    
    The command sends the phrase “I really love traveling to Spain. The architecture is beyond beautiful and the food exquisite", to the Cognitive Service Text Analytics API. The API responds with a number between 1 (positive sentiment) and 0 (negative sentiment).

### Use the Cognitive Services Bing Search API with the Kiosk application

1.  Switch back to the Azure portal in Internet Explorer
2.  Click **+ Create a resource**.
3.  In the search box, type **Bing Search**, and then press Enter.
4.  Click **Bing Search v7**, and then click **Create**.
5.  Specify the following parameters, and then click **Create**:
    -  **Name**: \<*yourname*\>-CSB
    -  **Subscription**: your classroom subscription
    -  **Pricing tier**: S1
    -  **Resource Group (Create new)**: \<*yourname*\>-CSBRG
    -  **Location**: your nearest location
    -  **I confirm I have read and understood the notice below**: selected
6.  In **Visual Studio 2015**, in the **IntelligentKioskSample** project, right-click the **IntelligentKioskSample** project, and then click **Set as StartUp Project**.
7.  Press F5 to start the application.
8.  In the **Intelligent Kiosk Sample** window, on the hamburger menu, in the upper left, click **Settings**.
9.  Switch to Internet Explorer displaying **portal.azure.com**.
10. Click **All resources**, click **\<*yourname*\>-CSA**, click **Keys**, and copy the value shown for **KEY 1** to the **Text Analytics Key** field in the **Settings** page of the Kiosk application.
11. Next to **Text Analytics Key**, in the **Region** drop-down list, click the region in which you created the Text Analytics service.
12. Return to Internet Explorer displaying **portal.azure.com**, click **All resources**, click **\<*yourname*\>-CSB**, click **Keys**, and copy the value shown for **KEY 1** to the **Bing Search API key** field in the **Settings** page of the Kiosk application.
13. On the hamburger menu, click **Demos**, and then click **Bing News Analytics**.
14. In the search box, type **California**, and then click **Search**.
15. Explore the results, noting any outliers in sentiment and clicking on a few news stories. 
16. Also, note the topics listed from the results.
17. Change the **Language** to **French** and notice the difference in articles.
18. Explore a few more search terms.
19. Leave the Kiosk application running for the next demonstration.

## Demo 2: Using Microsoft Kiosk with Image and Video APIs

### Scenario

In this demonstration, you will see how to: 
-  Configure the Kiosk application to use Microsoft Cognitive Services’ Face and Computer Vision APIs.
-  Use the Kiosk application to detect faces and facial expressions.

### Preparation

Before sharing this demo, take 3-5 pictures of yourself from different angles—and which are showing different emotions—then upload these pictures to your classroom computer. You will use these photos during emotion detection and facial detection during the demo. Alternatively, you can use the images in the **E:\\Demofiles\\Mod11** folder.

### Configure the Kiosk application to use Microsoft Cognitive Services’ Face, Emotion, and Computer Vision APIs

1.  In Internet Explorer, navigate to **https://portal.azure.com**.
2.  If prompted, sign in using the Microsoft account that is associated with your Azure Learning Pass subscription.
3.  Click **+ Create a resource**.
4.  In the search box, type **Face**, and then press Enter.
5.  Click **Face**, and then click **Create**.
6.  Specify the following parameters, and then click **Create**:
    -  **Account name**: \<*yourname*\>-CSC
    -  **Subscription**: your subscription
    -  **Location**: your nearest location
    -  **Pricing Tier**: S0
    -  **Resource Group (Create new)**: \<*yourname*\>-CSCRG
7.  After the Cognitive Service is created, click **All resources**, click your Cognitive Services account, click **Keys**, and copy the value shown for **KEY 1** to the clipboard. 
8.  Switch the **Intelligent Kiosk Application**.
9.  In the hamburger menu in the upper left, click **Settings**.
10. Paste the **\<*yourname*\>-CSC KEY 1** into the **Face API Key** box in the application’s settings.
11. Next to **Face API Key**, in the **Region** drop-down list, click the region in which you created the Face service.
12. Switch back to the Azure Portal, and repeat steps 3 to 11 to create a **Computer Vision** Cognitive Service API with the following settings:
    -  **Account name**: \<*yourname*\>-CV
    -  **Subscription**: your subscription
    -  **Location**: your nearest location
    -  **Pricing Tier**: S1
    -  **Resource Group (Create new)**: \<*yourname*\>-CVRG

### Use the Kiosk application to detect faces and facial expressions

1.  In the Kiosk application, in the hamburger menu, click **Demos**, and then click **Emotion API Explorer**.
2.  In the **Error starting the camera** dialog box, click **Close**.
3.  In the top right of the page, click the globe icon, and then click **Browse local files**.
4.  In the **Open** dialog box, browse to the **E:\Demofiles\Mod11** folder, and select any one of the jpeg files showing faces with different emotions, and see how the API reacts to the facial expressions.
5.  Repeat steps 3 and 4, selecting a different image.
6.  In the hamburger menu, click **Demos**, and then click **Face API Explorer**.
7.  In the **Error starting the camera** dialog box, click **Close**.
8.  In the top right of the page, click the globe icon, and then click **Browse local files**.
9.  In the **Open** dialog box, browse to the **E:\Demofiles\Mod11** folder, and select any one of the jpg files. Explore what the Face API returns.
10. Repeat steps 8 and 9, selecting a different image.

### Use the Kiosk application to analyze images

1.  In the Kiosk application, in the hamburger menu, click **Demos**, and then click **Vision API Explorer**.
2.  In the top right of the page, click the globe icon, and then click **Browse local files**.
3.  In the **Open** dialog box, browse to the **E:\Demofiles\Mod11**, and select any one of the jpg files. 
4.  Note the **Description** in the data returned by the Vision API.
5.  Repeat steps 2 and 3, selecting a different image.
6.  Close the Kiosk application, and then close Visual Studio 2015.

---

©2018 Microsoft Corporation. All rights reserved.

The text in this document is available under the [Creative Commons Attribution 3.0 License](https://creativecommons.org/licenses/by/3.0/legalcode), additional terms may apply. All other content contained in this document (including, without limitation, trademarks, logos, images, etc.) are **not** included within the Creative Commons license grant. This document does not provide you with any legal rights to any intellectual property in any Microsoft product. You may copy and use this document for your internal, reference purposes.

This document is provided "as-is." Information and views expressed in this document, including URL and other Internet Web site references, may change without notice. You bear the risk of using it. Some examples are for illustration only and are fictitious. No real association is intended or inferred. Microsoft makes no warranties, express or implied, with respect to the information provided here.
